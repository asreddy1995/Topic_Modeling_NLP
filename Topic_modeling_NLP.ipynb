{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b965cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c05be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\My Pc\\ML_project\\text\\text_summar\\Topic.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24149776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327337, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650697d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text=data[:300000][['headline_text']]\n",
    "data_text['index']=data_text.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e81cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717201c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total no of douments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0482dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa57c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text  index\n",
       "0  aba decides against community broadcasting lic...      0\n",
       "1     act fire witnesses must be aware of defamation      1\n",
       "2     a g calls for infrastructure protection summit      2\n",
       "3           air nz staff in aust strike for pay rise      3\n",
       "4      air nz strike to affect australian travellers      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6f00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing.\n",
    "#1.toeknization , stowpords, lemmatization, stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9364d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading gensim and nltk libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f42452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My Pc\\Anaconda3\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32bac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e79005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\My\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c72bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before preprocesiing our datset, lets first look at an lemmatizing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9332853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ee5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#throw a number of words at the stemmer and see how it deals with each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc0bfefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=SnowballStemmer('english')\n",
    "original_words=['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles=[stemmer.stem(plural) for plural in original_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4168d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'original word': original_words, 'stemmed':singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b91f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing the pre processing steps on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aa89e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer(). lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cb53a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview a document after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3833d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document\n",
      "['rain', 'helps', 'dampen', 'bushfires']\n",
      "['rain', 'help', 'dampen', 'bushfir']\n"
     ]
    }
   ],
   "source": [
    "document_num=4310\n",
    "doc_sample=documents[documents['index']==document_num].values[0][0]\n",
    "print('original document')\n",
    "words=[]\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b59725a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>broughton hall audit reveals serious breaches</td>\n",
       "      <td>299995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>broughton hall fails key standards</td>\n",
       "      <td>299996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>broughton hall safe for residents govt says</td>\n",
       "      <td>299997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>burn off at conservation park aims to prevent</td>\n",
       "      <td>299998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>burns suspended for two games</td>\n",
       "      <td>299999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline_text   index\n",
       "0       aba decides against community broadcasting lic...       0\n",
       "1          act fire witnesses must be aware of defamation       1\n",
       "2          a g calls for infrastructure protection summit       2\n",
       "3                air nz staff in aust strike for pay rise       3\n",
       "4           air nz strike to affect australian travellers       4\n",
       "...                                                   ...     ...\n",
       "299995      broughton hall audit reveals serious breaches  299995\n",
       "299996                 broughton hall fails key standards  299996\n",
       "299997        broughton hall safe for residents govt says  299997\n",
       "299998      burn off at conservation park aims to prevent  299998\n",
       "299999                      burns suspended for two games  299999\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d323aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing all the headlines , saving the list of results as 'processed_docs'\n",
    "processed_docs=documents['headline_text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bec480f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [decid, communiti, broadcast, licenc]\n",
       "1                               [wit, awar, defam]\n",
       "2           [call, infrastructur, protect, summit]\n",
       "3                      [staff, aust, strike, rise]\n",
       "4             [strike, affect, australian, travel]\n",
       "5               [ambiti, olsson, win, tripl, jump]\n",
       "6           [antic, delight, record, break, barca]\n",
       "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
       "8            [aust, address, secur, council, iraq]\n",
       "9                         [australia, lock, timet]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23ab370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words on the dataset\n",
    "#create a dictionary from precessed_docs containing the number of times a word appers in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "028a7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e593022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcast\n",
      "1 communiti\n",
      "2 decid\n",
      "3 licenc\n",
      "4 awar\n",
      "5 defam\n",
      "6 wit\n",
      "7 call\n",
      "8 infrastructur\n",
      "9 protect\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "#checking dictionary created\n",
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(k,v)\n",
    "    count+=1\n",
    "    if count>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea2d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove very rare and common words\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4560ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert document into bag-of-words format. each word is assumed to tokenize and normalized string\n",
    "bow_corpus=[dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea666cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(76, 1), (113, 1), (482, 1), (4016, 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking bag of words for ur sample dcument\n",
    "bow_corpus[document_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "102495b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 76('bushfir') appears 1 time\n",
      "word 113('help') appears 1 time\n",
      "word 482('rain') appears 1 time\n",
      "word 4016('dampen') appears 1 time\n"
     ]
    }
   ],
   "source": [
    "#preview bow for our sample preprocessed document\n",
    "bow_doc_4310=bow_corpus[document_num]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print('word {}(\\'{}\\') appears {} time'.format(bow_doc_4310[i][0], dictionary[bow_doc_4310[i][0]], bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e97551bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF on our document set\n",
    "#while perforing Tf-idf on the corpus is not necessary for LDA implementation using gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8bec476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tf-idf model object using modles\n",
    "from gensim import corpora, models\n",
    "tfidf=models.TfidfModel(bow_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31e91cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply tranformation to the entire corpus and call it 'corpus-tfidf'\n",
    "corpus_tfidf=tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3b95a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5959813347777092),\n",
      " (1, 0.39204529549491984),\n",
      " (2, 0.48531419274988147),\n",
      " (3, 0.5055461098578569)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c79af153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running LDA using Bag of words\n",
    "#train the lda mdel using gensim.models.LdaMulticore \n",
    "lda_model=gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a715f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0.035*\"polic\" + 0.019*\"opposit\" + 0.018*\"work\" + 0.017*\"call\" + 0.017*\"probe\" + 0.016*\"talk\" + 0.016*\"govt\" + 0.013*\"blaze\" + 0.010*\"threat\" + 0.010*\"push\" \n",
      "words:0\n",
      "\n",
      "\n",
      "topic 0.022*\"minist\" + 0.019*\"closer\" + 0.018*\"claim\" + 0.017*\"protest\" + 0.013*\"strike\" + 0.012*\"reject\" + 0.011*\"australia\" + 0.010*\"worker\" + 0.010*\"damag\" + 0.009*\"storm\" \n",
      "words:1\n",
      "\n",
      "\n",
      "topic 0.023*\"hospit\" + 0.017*\"report\" + 0.016*\"deal\" + 0.013*\"action\" + 0.011*\"find\" + 0.010*\"highlight\" + 0.010*\"inquiri\" + 0.009*\"bird\" + 0.009*\"rate\" + 0.008*\"studi\" \n",
      "words:2\n",
      "\n",
      "\n",
      "topic 0.038*\"govt\" + 0.022*\"fund\" + 0.020*\"urg\" + 0.016*\"boost\" + 0.012*\"water\" + 0.012*\"farmer\" + 0.011*\"price\" + 0.011*\"group\" + 0.011*\"drought\" + 0.010*\"help\" \n",
      "words:3\n",
      "\n",
      "\n",
      "topic 0.023*\"nation\" + 0.018*\"win\" + 0.016*\"rule\" + 0.010*\"final\" + 0.010*\"blue\" + 0.010*\"clash\" + 0.009*\"chang\" + 0.009*\"critic\" + 0.009*\"meet\" + 0.009*\"race\" \n",
      "words:4\n",
      "\n",
      "\n",
      "topic 0.024*\"polic\" + 0.019*\"jail\" + 0.016*\"arrest\" + 0.014*\"break\" + 0.012*\"land\" + 0.011*\"famili\" + 0.010*\"suspect\" + 0.010*\"warn\" + 0.010*\"timor\" + 0.010*\"east\" \n",
      "words:5\n",
      "\n",
      "\n",
      "topic 0.019*\"record\" + 0.016*\"coast\" + 0.016*\"law\" + 0.016*\"market\" + 0.016*\"busi\" + 0.015*\"time\" + 0.014*\"gold\" + 0.012*\"trade\" + 0.012*\"guilti\" + 0.011*\"drive\" \n",
      "words:6\n",
      "\n",
      "\n",
      "topic 0.035*\"kill\" + 0.030*\"crash\" + 0.027*\"death\" + 0.022*\"polic\" + 0.018*\"road\" + 0.017*\"investig\" + 0.014*\"die\" + 0.014*\"attack\" + 0.014*\"driver\" + 0.013*\"fear\" \n",
      "words:7\n",
      "\n",
      "\n",
      "topic 0.047*\"council\" + 0.043*\"plan\" + 0.034*\"charg\" + 0.030*\"court\" + 0.029*\"face\" + 0.024*\"water\" + 0.013*\"murder\" + 0.012*\"concern\" + 0.010*\"consid\" + 0.010*\"develop\" \n",
      "words:8\n",
      "\n",
      "\n",
      "topic 0.024*\"miss\" + 0.018*\"lead\" + 0.016*\"search\" + 0.015*\"open\" + 0.013*\"aussi\" + 0.012*\"close\" + 0.011*\"continu\" + 0.010*\"world\" + 0.009*\"england\" + 0.009*\"fight\" \n",
      "words:9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fr each topic we will explore the words occuring in that topic and its relative weight\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('topic {} \\nwords:{}'.format(topic,idx))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6da14d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rain', 'help', 'dampen', 'bushfir']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performance evalution by classifying sample documents using LDA Bag of words\n",
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33a66e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score:0.4705457389354706\t \n",
      "topic 0.038*\"govt\" + 0.022*\"fund\" + 0.020*\"urg\" + 0.016*\"boost\" + 0.012*\"water\" + 0.012*\"farmer\" + 0.011*\"price\" + 0.011*\"group\" + 0.011*\"drought\" + 0.010*\"help\"\n",
      "\n",
      "score:0.3694206178188324\t \n",
      "topic 0.023*\"hospit\" + 0.017*\"report\" + 0.016*\"deal\" + 0.013*\"action\" + 0.011*\"find\" + 0.010*\"highlight\" + 0.010*\"inquiri\" + 0.009*\"bird\" + 0.009*\"rate\" + 0.008*\"studi\"\n",
      "\n",
      "score:0.020006079226732254\t \n",
      "topic 0.035*\"polic\" + 0.019*\"opposit\" + 0.018*\"work\" + 0.017*\"call\" + 0.017*\"probe\" + 0.016*\"talk\" + 0.016*\"govt\" + 0.013*\"blaze\" + 0.010*\"threat\" + 0.010*\"push\"\n",
      "\n",
      "score:0.02000470831990242\t \n",
      "topic 0.022*\"minist\" + 0.019*\"closer\" + 0.018*\"claim\" + 0.017*\"protest\" + 0.013*\"strike\" + 0.012*\"reject\" + 0.011*\"australia\" + 0.010*\"worker\" + 0.010*\"damag\" + 0.009*\"storm\"\n",
      "\n",
      "score:0.020004503428936005\t \n",
      "topic 0.019*\"record\" + 0.016*\"coast\" + 0.016*\"law\" + 0.016*\"market\" + 0.016*\"busi\" + 0.015*\"time\" + 0.014*\"gold\" + 0.012*\"trade\" + 0.012*\"guilti\" + 0.011*\"drive\"\n",
      "\n",
      "score:0.020003948360681534\t \n",
      "topic 0.024*\"miss\" + 0.018*\"lead\" + 0.016*\"search\" + 0.015*\"open\" + 0.013*\"aussi\" + 0.012*\"close\" + 0.011*\"continu\" + 0.010*\"world\" + 0.009*\"england\" + 0.009*\"fight\"\n",
      "\n",
      "score:0.020003804937005043\t \n",
      "topic 0.035*\"kill\" + 0.030*\"crash\" + 0.027*\"death\" + 0.022*\"polic\" + 0.018*\"road\" + 0.017*\"investig\" + 0.014*\"die\" + 0.014*\"attack\" + 0.014*\"driver\" + 0.013*\"fear\"\n",
      "\n",
      "score:0.020003629848361015\t \n",
      "topic 0.047*\"council\" + 0.043*\"plan\" + 0.034*\"charg\" + 0.030*\"court\" + 0.029*\"face\" + 0.024*\"water\" + 0.013*\"murder\" + 0.012*\"concern\" + 0.010*\"consid\" + 0.010*\"develop\"\n",
      "\n",
      "score:0.020003484562039375\t \n",
      "topic 0.024*\"polic\" + 0.019*\"jail\" + 0.016*\"arrest\" + 0.014*\"break\" + 0.012*\"land\" + 0.011*\"famili\" + 0.010*\"suspect\" + 0.010*\"warn\" + 0.010*\"timor\" + 0.010*\"east\"\n",
      "\n",
      "score:0.02000344730913639\t \n",
      "topic 0.023*\"nation\" + 0.018*\"win\" + 0.016*\"rule\" + 0.010*\"final\" + 0.010*\"blue\" + 0.010*\"clash\" + 0.009*\"chang\" + 0.009*\"critic\" + 0.009*\"meet\" + 0.009*\"race\"\n"
     ]
    }
   ],
   "source": [
    "#check which topic our test document belongs to using LDA Bag of words model\n",
    "document_num=4310\n",
    "#our test document in document number\n",
    "for index, score in sorted(lda_model[bow_corpus[document_num]], key=lambda tup: -1*tup[1]):\n",
    "    print('\\nscore:{}\\t \\ntopic {}'.format(score, lda_model.print_topic(index,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aba64b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing mdel on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb5d3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document='My favourite sports are running and playing cricket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f6802d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.56449294090271 \t Topic:0.022*\"minist\" + 0.019*\"closer\" + 0.018*\"claim\" + 0.017*\"protest\" + 0.013*\"strike\"\n",
      "score 0.17790427803993225 \t Topic:0.019*\"record\" + 0.016*\"coast\" + 0.016*\"law\" + 0.016*\"market\" + 0.016*\"busi\"\n",
      "score 0.1408858448266983 \t Topic:0.023*\"nation\" + 0.018*\"win\" + 0.016*\"rule\" + 0.010*\"final\" + 0.010*\"blue\"\n",
      "score 0.01668582484126091 \t Topic:0.024*\"miss\" + 0.018*\"lead\" + 0.016*\"search\" + 0.015*\"open\" + 0.013*\"aussi\"\n",
      "score 0.01667320355772972 \t Topic:0.023*\"hospit\" + 0.017*\"report\" + 0.016*\"deal\" + 0.013*\"action\" + 0.011*\"find\"\n",
      "score 0.016672460362315178 \t Topic:0.024*\"polic\" + 0.019*\"jail\" + 0.016*\"arrest\" + 0.014*\"break\" + 0.012*\"land\"\n",
      "score 0.016672244295477867 \t Topic:0.047*\"council\" + 0.043*\"plan\" + 0.034*\"charg\" + 0.030*\"court\" + 0.029*\"face\"\n",
      "score 0.01667158491909504 \t Topic:0.035*\"kill\" + 0.030*\"crash\" + 0.027*\"death\" + 0.022*\"polic\" + 0.018*\"road\"\n",
      "score 0.016671322286128998 \t Topic:0.035*\"polic\" + 0.019*\"opposit\" + 0.018*\"work\" + 0.017*\"call\" + 0.017*\"probe\"\n",
      "score 0.016670359298586845 \t Topic:0.038*\"govt\" + 0.022*\"fund\" + 0.020*\"urg\" + 0.016*\"boost\" + 0.012*\"water\"\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing step for unseen document\n",
    "bow_vector=dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup : -1*tup[1]):\n",
    "    print('score {} \\t Topic:{}'. format(score, lda_model.print_topic(index,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae849b",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
